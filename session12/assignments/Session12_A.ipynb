{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TinyImagenet training\n",
    "\n",
    "### A. Target\n",
    "\n",
    "Move your last code's transformations to Albumentations. Apply ToTensor, HorizontalFlip, Normalize (at min) + More (for additional points)\n",
    "Please make sure that your test_transforms are simple and only using ToTensor and Normalize\n",
    "Implement GradCam function as a module.\n",
    "Your final code (notebook file) must use imported functions to implement transformations and GradCam functionality\n",
    "Target Accuracy is 87%\n",
    "\n",
    "### B. Results\n",
    "\n",
    "Parameters: 11,173,962\n",
    "Best Training Accuracy in 30 epochs: 96.51%\n",
    "Best Test Accuracy in 30 epochs: 87.96 %\n",
    "Total RF reached: 76*76 at the end of Conv block 4\n",
    "\n",
    "### C. Analysis\n",
    "\n",
    "I have implemented Albumentations transforms for normalization ( by finding norm and std values for entire dataset ), Horizontal flip, Vertical flip, Rotations. This acts as a regularizer and now the model is not overfitting to the extent it was earlier\n",
    "\n",
    "I have also implemented the grad cam functionality and results are displayed for few of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "import albumentations as A\n",
    "from collections import Sequence\n",
    "import numpy as np\n",
    "\n",
    "from   torch.utils.data import Dataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/SachinDangayach/EVA5\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path\n",
    "sys.path.append(r'C:\\Users\\sdangayach162437\\Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai_eva5_work.session11.dataset import session11_dataset as dataset\n",
    "from tsai_eva5_work.session11.models import session11 as models\n",
    "from tsai_eva5_work.session11.models import session11_train_model as train\n",
    "from tsai_eva5_work.session11.models import session11_test_model as test\n",
    "from tsai_eva5_work.session9.utils import session9_utils as utils\n",
    "from tsai_eva5_work.session11.utils import session11_lr_test as lr_test\n",
    "from tsai_eva5_work.session10.utils import session10_lr_finder as lr_finder\n",
    "from tsai_eva5_work.session9.utils import session9_view_gradcam as grad_cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "channel_means = (0.442,0.442,0.442)\n",
    "channel_stdevs = (0.278, 0.278, 0.278)\n",
    "train_transform = AlbumentationTransforms([       \n",
    "                                                                \n",
    "                                      A.HorizontalFlip(p = 0.7),\n",
    "                                      A.PadIfNeeded(min_height=70, min_width=70, border_mode=4, value=None, mask_value=None, always_apply=False, p=1.0),\n",
    "                                      A.RandomCrop(64, 64, always_apply=False, p=1.0),\n",
    "                                      A.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n",
    "                                      A.Normalize(mean=channel_means, std=channel_stdevs),\n",
    "                                      A.Cutout(num_holes=1, max_h_size=32,max_w_size = 32,p=0.7) \n",
    "                                       ])\n",
    "test_transform = AlbumentationTransforms([A.Normalize(mean=channel_means, std=channel_stdevs)])\n",
    "train_dataset , test_dataset,classes = TinyImageNetDataSet(train_split = 70,test_transforms = test_transform,train_transforms = train_transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
